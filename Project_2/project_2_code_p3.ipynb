{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Clustering using both image and text\n",
    "\n",
    "In part 1 and part 2, we have practived the art of clustering text and images separately.\n",
    "However, can we map image and text to the same space? In the Pokemon world, Pokedex\n",
    "catalogs Pokemon’s appearances and various metadata. We will build our Pokedex from image\n",
    "dataset link and meta metadata link. Fortunately, ECE 219 Gym kindly provides new Pokemon\n",
    "trainers with the helper code for data preprocessing and inferencing. Please find the code on\n",
    "Bruinlearn modules Week 4.\n",
    "\n",
    "We will use the pre-trained CLIP [8] to illustrate the idea of multimodal clustering. CLIP\n",
    "(Contrastive Language–Image Pretraining) is an innovative model developed by OpenAI, de-\n",
    "signed to understand and connect concepts from both text and images. CLIP is trained on a\n",
    "vast array of internet-sourced text-image pairs. This extensive training enables the model to\n",
    "understand a broad spectrum of visual concepts and their textual descriptions.\n",
    "\n",
    "CLIP consists of two primary components: a text encoder and an image encoder. The text\n",
    "encoder processes textual data, converting sentences and phrases into numerical representa-\n",
    "tions. Simultaneously, the image encoder transforms visual inputs into a corresponding set\n",
    "of numerical values. These encoders are trained to map both text and images into a shared\n",
    "embedding space, allowing the model to compare and relate the two different types of data di-\n",
    "rectly. The training employs a contrastive learning approach, where the model learns to match\n",
    "corresponding text and image pairs against numerous non-matching pairs. This approach helps\n",
    "the model in accurately associating images with their relevant textual descriptions and vice\n",
    "versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece219",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
