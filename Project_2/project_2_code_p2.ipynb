{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Deep Learning and Clustering of Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we use a VGG network [6] pre-trained on the ImageNet dataset [7]. We\n",
    "provide a helper codebase (check Week 4 in BruinLearn), which guides you through the\n",
    "necessary steps for loading the VGG network and for using it for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q19 Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 19: \n",
    "In a brief paragraph discuss: If the VGG network is trained on a dataset with\n",
    "perhaps totally different classes as targets, why would one expect the features derived from such a\n",
    "network to have discriminative power for a custom dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the helper code to load the flowers dataset, and extract their features. To perform\n",
    "computations on deep neural networks fast enough, GPU resources are often required. GPU\n",
    "resources can be freely accessed through “Google Colab”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q20 Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 20: \n",
    "In a brief paragraph explain how the helper code base is performing feature\n",
    "extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 21:\n",
    "How many pixels are there in the original images? How many features does\n",
    "the VGG network extract per image; i.e what is the dimension of each feature vector for an image\n",
    "sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 22:\n",
    "Are the extracted features dense or sparse? (Compare with sparse TF-IDF\n",
    "features in text.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 23:\n",
    "In order to inspect the high-dimensional features, t-SNE is a popular off-the-shelf\n",
    "choice for visualizing Vision features. Map the features you have extracted onto 2 dimensions with\n",
    "t-SNE. Then plot the mapped feature vectors along x and y axes. Color-code the data points with\n",
    "ground-truth labels. Describe your observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q23 Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While PCA is a powerful method for dimensionality reduction, it is limited to “linear”\n",
    "transformations. This might not be particularly good if a dataset is distributed non-linearly.\n",
    "An alternative approach is use of an “autoencoder” or UMAP. The helper has implemented an\n",
    "autoencoder which is ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 24:\n",
    "Report the best result (in terms of rand score) within the table below.\n",
    "For HDBSCAN, introduce a conservative parameter grid over min cluster size and min samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Q24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANSWER:\n",
    "\n",
    "| Module | Alternatives | Hyperparameters |\n",
    "| :---: | ----- | ----- |\n",
    "|  Dimensionality Reduction | None | N/A |\n",
    "|  | SVD | r \\= 50 |\n",
    "|  | UMAP | n\\_components \\= 50 |\n",
    "|  | Autoencoder | num\\_features \\= 50 |\n",
    "|  Clustering | K-Means | k \\= 5 |\n",
    "|  | Agglomerative Clustering | n\\_clusters \\= 5 |\n",
    "|  | HDBSCAN | Min\\_cluster\\_size & min\\_samples |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can conduct an experiment to ensure that VGG features are rich enough in\n",
    "information about the data classes. In particular, we can train a fully-connected neural network\n",
    "classifier to predict the labels of data. For this task, you may use the MLP4 module provided in\n",
    "the helper code base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 25:\n",
    "Report the test accuracy of the MLP classifier on the original VGG features.\n",
    "Report the same when using the reduced-dimension features (you have freedom in choosing the\n",
    "dimensionality reduction algorithm and its parameters). Does the performance of the model suffer\n",
    "with the reduced-dimension representations? Is it significant? Does the success in classification\n",
    "make sense in the context of the clustering results obtained for the same features in Question 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Q24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece219",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
